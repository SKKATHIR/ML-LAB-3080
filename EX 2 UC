import math
from collections import Counter

# Dataset
data = [
    {"Fever": "High", "Cough": "Yes", "Fatigue": "Yes", "Age": "Old", "Disease": "Yes"},
    {"Fever": "High", "Cough": "Yes", "Fatigue": "No", "Age": "Young", "Disease": "Yes"},
    {"Fever": "Normal", "Cough": "Yes", "Fatigue": "Yes", "Age": "Old", "Disease": "Yes"},
    {"Fever": "Low", "Cough": "No", "Fatigue": "No", "Age": "Young", "Disease": "No"}
]

# Calculate Entropy
def entropy(data):
    labels = [row["Disease"] for row in data]
    total = len(labels)
    counts = Counter(labels)
    
    ent = 0
    for count in counts.values():
        p = count / total
        ent -= p * math.log2(p)
    return ent

# Calculate Information Gain
def information_gain(data, attribute):
    total_entropy = entropy(data)
    total = len(data)
    
    values = set(row[attribute] for row in data)
    weighted_entropy = 0
    
    for value in values:
        subset = [row for row in data if row[attribute] == value]
        weighted_entropy += (len(subset) / total) * entropy(subset)
    
    return total_entropy - weighted_entropy

# ID3 Algorithm
def id3(data, attributes):
    labels = [row["Disease"] for row in data]
    
    # If all examples same class
    if labels.count(labels[0]) == len(labels):
        return labels[0]
    
    # If no attributes left
    if not attributes:
        return Counter(labels).most_common(1)[0][0]
    
    # Select best attribute
    gains = [(attribute, information_gain(data, attribute)) for attribute in attributes]
    best_attribute = max(gains, key=lambda x: x[1])[0]
    
    tree = {best_attribute: {}}
    
    values = set(row[best_attribute] for row in data)
    
    for value in values:
        subset = [row for row in data if row[best_attribute] == value]
        
        if not subset:
            tree[best_attribute][value] = Counter(labels).most_common(1)[0][0]
        else:
            remaining_attributes = [attr for attr in attributes if attr != best_attribute]
            tree[best_attribute][value] = id3(subset, remaining_attributes)
    
    return tree

# Attributes list
attributes = ["Fever", "Cough", "Fatigue", "Age"]

# Build Decision Tree
decision_tree = id3(data, attributes)

print("Decision Tree:")
print(decision_tree)
Output:

Decision Tree:
{'Fever': {'High': 'Yes', 'Low': 'No', 'Normal': 'Yes'}}
